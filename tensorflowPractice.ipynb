{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 기초\n",
    "1. tensorflow란\n",
    "    * tensor는 데이터를 담는 다차원 배열.\n",
    "    * 이것의 흐름을 tensorflow라고 표현.\n",
    "    * 수학적인 계산을 각 node와 edge로 표현함\n",
    "    * node는 수학적 계산, edge는 데이터의 입출력 표현\n",
    "2. 이러한 tensorflow의 계산, 데이터 흐름을 나타낸 것을 **Graph**라고 함.(*수학 용어로 node와 edge를 나타낸 것.*)\n",
    "    * graph상의 Node를 Opeartion(계산) 이라고 함.\n",
    "    * graph를 실행하기 위해서는 항상 Session 객체가 필요함. Session()클래스로 생성.\n",
    "        * Session은 오퍼레이션의 실행환경을 캡슐화 한 것.\n",
    "    * 변수는 그래프의 실행시 패러미터를 저장하고 갱신하는 데에 사용. *메모리 상의 텐서를 저장하는 **버퍼** 역할*\n",
    "![Image of Tensorflow](https://camo.githubusercontent.com/4ee55154486232ec9edd8f1a3bad4c4a146f6cfe/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f74656e736f72735f666c6f77696e672e676966)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, tensorflow!\n"
     ]
    }
   ],
   "source": [
    "#tensorflow 상수\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "hello = tf.constant('hello, tensorflow!')\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print sess.run(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor끼리는 그냥 계산을 할 수가 없다.\n",
    "* **Session** 속에서 계산을 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(3)\n",
    "b = tf.constant(4)\n",
    "c = a+b\n",
    "# node\n",
    "# deferred caculation\n",
    "# 왜 그런 것일까?\n",
    "# 미분을 쫙 해주기 위해서. 미분에 용이하다고 함.\n",
    "# 분산처리가 가능하게 하기 위해서.\n",
    "\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 변수를 0 으로 초기화.\n",
    "state = tf.Variable(0, name='counter')\n",
    "\n",
    "\n",
    "# state 에 1 을 더할 Operator 생성 (node가 하나 만들어지는 것.)\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# graph는 처음에 변수 초기화가 필수\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print(sess.run(state))\n",
    "    \n",
    "    for _ in range (3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 경사 하강법으로 인자 찾아내기\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hs.o/.pyenv/versions/2.7.8/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#결정해야하는 변수는 계수.\n",
    "# y= a x1 + b x2 + c\n",
    "#(실제 y - a x1 + bx2 + c)^2 => minimize a,b,c\n",
    "# matlab * 1. cost-function  2. gradient\n",
    "\n",
    "#random data\n",
    "x_data = np.float32(np.random.rand(2,100))\n",
    "\n",
    "print(x_data.shape)\n",
    "print type(x_data)\n",
    "\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "y = tf.matmul(W, x_data) + b\n",
    "\n",
    "#손실 함수 정의\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "#gradient Descent 객체를 가져오기\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "\n",
    "#Deep 해 질수록 , 변수가 많아질수록 발산하기가 쉬워지기 때문에 작은 값을 쓰는 것이 좋다!\n",
    "\n",
    "#train 노드 정의\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12836501  0.26094443]] [ 0.25330815]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAFoCAYAAADzZ0kIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae53910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "#변수 초기화 노드\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "for i in xrange(0,20000):\n",
    "    sess.run(train)\n",
    "\n",
    "    loss_list.append(sess.run(loss))\n",
    "    \n",
    "plt.plot(loss_list)\n",
    "print sess.run(W), sess.run(b)\n",
    "#     print sess.run(loss), sess.run(W), sess.run(b)\n",
    "    \n",
    "# fig = plt.figure()\n",
    "# theta1 = sess.run(W)[0][0]\n",
    "# theta2 = sess.run(W)[0][1]\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# X = x_data[0]\n",
    "# Y = x_data[1]\n",
    "# Z = np.dot([theta1, theta2], x_data) + sess.run(b)[0]\n",
    "# ax.plot_surface(X,Y,Z, rstride=4, cstride=4, color='b')\n",
    "\n",
    "# print sess.run(W), sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male  28.0      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "train = pd.read_csv('./train.csv')\n",
    "train['Embarked'] = train['Embarked'].fillna(\"S\")\n",
    "train['Pclass'] = train['Pclass'].fillna(1) \n",
    "train[\"Fare\"].fillna(train[\"Fare\"].mean(), inplace=True)\n",
    "train[\"Age\"].fillna(train[\"Age\"].median(), inplace=True)\n",
    "train[\"SibSp\"].fillna(train[\"SibSp\"].median(), inplace=True)\n",
    "train[\"Parch\"].fillna(train[\"Parch\"].median(), inplace=True)\n",
    "# train[\"\"]\n",
    "\n",
    "\n",
    "test = pd.read_csv('./test.csv')\n",
    "test[\"Fare\"].fillna(test[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# train.head(10)\n",
    "\n",
    "a = train['Survived']\n",
    "\n",
    "# train.drop(['Survived'], axis=1, inplace=True)\n",
    "\n",
    "# train.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "pids = train['PassengerId']\n",
    "\n",
    "dummy_sex = pd.get_dummies(train['Sex'])\n",
    "dummy_embarked = pd.get_dummies(train['Embarked'])\n",
    "dummy_pclass = pd.get_dummies(train['Pclass'])\n",
    "\n",
    "age = train['Age'].astype(np.float32)\n",
    "sibSp = train['SibSp'].astype(np.float32)\n",
    "parch = train['Parch'].astype(np.float32)\n",
    "fare = train['Fare'].astype(np.float32)\n",
    "\n",
    "dummy_data = dummy_sex.join(dummy_pclass).join(age).join(sibSp).join(dummy_embarked)\n",
    "# print (dummy_data.info())\n",
    "# for i in xrange(800):\n",
    "#     print type(fare[i])\n",
    "\n",
    "print dummy_data.shape\n",
    "\n",
    "# print(dummy_data.head(5))\n",
    "\n",
    "X = dummy_data.as_matrix()\n",
    "X = np.float32(X)\n",
    "Y = np.float32(train['Survived'].as_matrix())\n",
    "theta_dimension = dummy_data.shape[1]\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693531\n",
      "0 0.671705\n",
      "20 0.670291\n",
      "40 0.670144\n",
      "60 0.66985\n",
      "80 0.669754\n",
      "100 0.669659\n",
      "120 0.669591\n",
      "140 0.66948\n",
      "160 0.669353\n",
      "180 0.669341\n",
      "200 0.669182\n",
      "220 0.66908\n",
      "240 0.669074\n",
      "260 0.668935\n",
      "280 0.668845\n",
      "300 0.668753\n",
      "320 0.668697\n",
      "340 0.668721\n",
      "360 0.668695\n",
      "380 0.668499\n",
      "400 0.668361\n",
      "420 0.668235\n",
      "440 0.668264\n",
      "460 0.668339\n",
      "480 0.668218\n",
      "500 0.668226\n",
      "520 0.668219\n",
      "540 0.668095\n",
      "560 0.667995\n",
      "580 0.668037\n",
      "600 0.667976\n",
      "620 0.667885\n",
      "640 0.667885\n",
      "660 0.667801\n",
      "680 0.667845\n",
      "700 0.667848\n",
      "720 0.667827\n",
      "740 0.667782\n",
      "760 0.667675\n",
      "780 0.667564\n",
      "800 0.667571\n",
      "820 0.667566\n",
      "840 0.667549\n",
      "860 0.667439\n",
      "880 0.667444\n",
      "900 0.667444\n",
      "920 0.667383\n",
      "940 0.66738\n",
      "960 0.667372\n",
      "980 0.66736\n",
      "1000 0.667369\n",
      "1020 0.667396\n",
      "1040 0.667331\n",
      "1060 0.667368\n",
      "1080 0.667353\n",
      "1100 0.667326\n",
      "1120 0.667236\n",
      "1140 0.667303\n",
      "1160 0.667226\n",
      "1180 0.667216\n",
      "1200 0.66726\n",
      "1220 0.667267\n",
      "1240 0.667265\n",
      "1260 0.667194\n",
      "1280 0.667186\n",
      "1300 0.667083\n",
      "1320 0.667064\n",
      "1340 0.667011\n",
      "1360 0.666905\n",
      "1380 0.666876\n",
      "1400 0.66687\n",
      "1420 0.666879\n",
      "1440 0.666855\n",
      "1460 0.666922\n",
      "1480 0.666835\n"
     ]
    }
   ],
   "source": [
    "#변수 W와 b\n",
    "W = tf.Variable(tf.random_uniform([theta_dimension, 1], 0, 0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "#cost값 구하기\n",
    "h = tf.matmul(X, W) + b\n",
    "hypothesis = tf.div(1.0 , 1.0 + tf.exp(-h))\n",
    "cost_sum = Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis)\n",
    "cost = tf.reduce_mean(-cost_sum)\n",
    "\n",
    "#train node만들기\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.005)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#계산 시작\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#cost 를 plot해보자!\n",
    "cost_list =[]\n",
    "# print sess.run(h)\n",
    "# print sess.run(hypothesis)\n",
    "# print sess.run(W).shape\n",
    "# print X.shape\n",
    "# print sess.run(h).shape\n",
    "# print sess.run(hypothesis)\n",
    "# print np.isnan(sess.run(cost_sum)).any()\n",
    "# print sess.run(cost_sum)\n",
    "# print np.isnan(sess.run(cost)).any()\n",
    "# print sess.run(cost)\n",
    "# print sess.run(train)\n",
    "# print (sess.run(cost))\n",
    "\n",
    "print sess.run(cost)\n",
    "# print sess.run(train)\n",
    "for step in xrange(10000):\n",
    "\n",
    "    sess.run(train)\n",
    "    cost_list.append(sess.run(cost))\n",
    "    if step % 20 == 0:\n",
    "        print step, sess.run(cost)\n",
    "\n",
    "plt.plot(cost_list)\n",
    "weight = sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1)\n",
      "(891, 1)\n",
      "0.412764\n",
      "0.400499\n",
      "0.414965\n",
      "0.399937\n",
      "0.395382\n",
      "0.418062\n",
      "0.369595\n",
      "0.435701\n",
      "0.412924\n",
      "0.446122\n",
      "0.451261\n",
      "0.363076\n",
      "0.425907\n",
      "0.378587\n",
      "0.439661\n",
      "0.365482\n",
      "0.435203\n",
      "0.418217\n",
      "0.395873\n",
      "0.417577\n",
      "0.403963\n",
      "0.40599\n",
      "0.446254\n",
      "0.421833\n",
      "0.424694\n",
      "0.381881\n",
      "0.416225\n",
      "0.413137\n",
      "0.419416\n",
      "0.409541\n",
      "0.40405\n",
      "0.420853\n",
      "0.419416\n",
      "0.343048\n",
      "0.419498\n",
      "0.384576\n",
      "0.416225\n",
      "0.423851\n",
      "0.413262\n",
      "0.437302\n",
      "0.377918\n",
      "0.412588\n",
      "0.416225\n",
      "0.469083\n",
      "0.437955\n",
      "0.409541\n",
      "0.409051\n",
      "0.419416\n",
      "0.398288\n",
      "0.4223\n",
      "0.416334\n",
      "0.423851\n",
      "0.378501\n",
      "0.408517\n",
      "0.354593\n",
      "0.421833\n",
      "0.433975\n",
      "0.415203\n",
      "0.458044\n",
      "0.399237\n",
      "0.428537\n",
      "0.402801\n",
      "0.378621\n",
      "0.431569\n",
      "0.428572\n",
      "0.407226\n",
      "0.417524\n",
      "0.427965\n",
      "0.39738\n",
      "0.395715\n",
      "0.410054\n",
      "0.390517\n",
      "0.432609\n",
      "0.411293\n",
      "0.40143\n",
      "0.415657\n",
      "0.409541\n",
      "0.409541\n",
      "0.474634\n",
      "0.406821\n",
      "0.421799\n",
      "0.407508\n",
      "0.419416\n",
      "0.421833\n",
      "0.442257\n",
      "0.374297\n",
      "0.425049\n",
      "0.409541\n",
      "0.406345\n",
      "0.417701\n",
      "0.407508\n",
      "0.425907\n",
      "0.376644\n",
      "0.404633\n",
      "0.348276\n",
      "0.409541\n",
      "0.343129\n",
      "0.438902\n",
      "0.407332\n",
      "0.397062\n",
      "0.410887\n",
      "0.409541\n",
      "0.436256\n",
      "0.39941\n",
      "0.373816\n",
      "0.409541\n",
      "0.42521\n",
      "0.409541\n",
      "0.389365\n",
      "0.410396\n",
      "0.383416\n",
      "0.436267\n",
      "0.421799\n",
      "0.418201\n",
      "0.440237\n",
      "0.423851\n",
      "0.334427\n",
      "0.407173\n",
      "0.436831\n",
      "0.42795\n",
      "0.414468\n",
      "0.409541\n",
      "0.406722\n",
      "0.410382\n",
      "0.369595\n",
      "0.440074\n",
      "0.418062\n",
      "0.417701\n",
      "0.408569\n",
      "0.37546\n",
      "0.406043\n",
      "0.425907\n",
      "0.364177\n",
      "0.408517\n",
      "0.424369\n",
      "0.435249\n",
      "0.441769\n",
      "0.394577\n",
      "0.434154\n",
      "0.436831\n",
      "0.417577\n",
      "0.423156\n",
      "0.410038\n",
      "0.436586\n",
      "0.438813\n",
      "0.427625\n",
      "0.411576\n",
      "0.431731\n",
      "0.400929\n",
      "0.38987\n",
      "0.372019\n",
      "0.426444\n",
      "0.354988\n",
      "0.384377\n",
      "0.409541\n",
      "0.381981\n",
      "0.444176\n",
      "0.405479\n",
      "0.409541\n",
      "0.340042\n",
      "0.377435\n",
      "0.395208\n",
      "0.413615\n",
      "0.432088\n",
      "0.428647\n",
      "0.448671\n",
      "0.423191\n",
      "0.368082\n",
      "0.421833\n",
      "0.409541\n",
      "0.355984\n",
      "0.431072\n",
      "0.457517\n",
      "0.423851\n",
      "0.372103\n",
      "0.420943\n",
      "0.382883\n",
      "0.385286\n",
      "0.414129\n",
      "0.393373\n",
      "0.341291\n",
      "0.424941\n",
      "0.412252\n",
      "0.455792\n",
      "0.460477\n",
      "0.421833\n",
      "0.410396\n",
      "0.387401\n",
      "0.384893\n",
      "0.393373\n",
      "0.4114\n",
      "0.436743\n",
      "0.420249\n",
      "0.46084\n",
      "0.397306\n",
      "0.369476\n",
      "0.418062\n",
      "0.381396\n",
      "0.419416\n",
      "0.427787\n",
      "0.409541\n",
      "0.340042\n",
      "0.397394\n",
      "0.380955\n",
      "0.430025\n",
      "0.464659\n",
      "0.392536\n",
      "0.420318\n",
      "0.444176\n",
      "0.40405\n",
      "0.417701\n",
      "0.405303\n",
      "0.421799\n",
      "0.414129\n",
      "0.409051\n",
      "0.414715\n",
      "0.412924\n",
      "0.381068\n",
      "0.421709\n",
      "0.414129\n",
      "0.434154\n",
      "0.420265\n",
      "0.363702\n",
      "0.409541\n",
      "0.392569\n",
      "0.421799\n",
      "0.436743\n",
      "0.424879\n",
      "0.438813\n",
      "0.384198\n",
      "0.399937\n",
      "0.407508\n",
      "0.356438\n",
      "0.421784\n",
      "0.426425\n",
      "0.410887\n",
      "0.377109\n",
      "0.461004\n",
      "0.436743\n",
      "0.40802\n",
      "0.408569\n",
      "0.410396\n",
      "0.416172\n",
      "0.421799\n",
      "0.412143\n",
      "0.380125\n",
      "0.417008\n",
      "0.427787\n",
      "0.394577\n",
      "0.357563\n",
      "0.409541\n",
      "0.399903\n",
      "0.354058\n",
      "0.396554\n",
      "0.384698\n",
      "0.415533\n",
      "0.429935\n",
      "0.419089\n",
      "0.415567\n",
      "0.37529\n",
      "0.418062\n",
      "0.424532\n",
      "0.36487\n",
      "0.397428\n",
      "0.419416\n",
      "0.40194\n",
      "0.398062\n",
      "0.406661\n",
      "0.363076\n",
      "0.408886\n",
      "0.421833\n",
      "0.415657\n",
      "0.393199\n",
      "0.410141\n",
      "0.419416\n",
      "0.344963\n",
      "0.376766\n",
      "0.418217\n",
      "0.424895\n",
      "0.387855\n",
      "0.344802\n",
      "0.409541\n",
      "0.434154\n",
      "0.427965\n",
      "0.421833\n",
      "0.406043\n",
      "0.405479\n",
      "0.421799\n",
      "0.38987\n",
      "0.431753\n",
      "0.427302\n",
      "0.439408\n",
      "0.408585\n",
      "0.419055\n",
      "0.417701\n",
      "0.428572\n",
      "0.42545\n",
      "0.468008\n",
      "0.421833\n",
      "0.385286\n",
      "0.419416\n",
      "0.400101\n",
      "0.427965\n",
      "0.42815\n",
      "0.409541\n",
      "0.468885\n",
      "0.429935\n",
      "0.443556\n",
      "0.411806\n",
      "0.425817\n",
      "0.4382\n",
      "0.43234\n",
      "0.414628\n",
      "0.409541\n",
      "0.379086\n",
      "0.414965\n",
      "0.418717\n",
      "0.366143\n",
      "0.417043\n",
      "0.396466\n",
      "0.421799\n",
      "0.411576\n",
      "0.424036\n",
      "0.422817\n",
      "0.340042\n",
      "0.413526\n",
      "0.344467\n",
      "0.403278\n",
      "0.395873\n",
      "0.454829\n",
      "0.401437\n",
      "0.386403\n",
      "0.401464\n",
      "0.415995\n",
      "0.414148\n",
      "0.409541\n",
      "0.410761\n",
      "0.403364\n",
      "0.37546\n",
      "0.387401\n",
      "0.462931\n",
      "0.404317\n",
      "0.418217\n",
      "0.424369\n",
      "0.40194\n",
      "0.427787\n",
      "0.395208\n",
      "0.401924\n",
      "0.451966\n",
      "0.381396\n",
      "0.419748\n",
      "0.421833\n",
      "0.433866\n",
      "0.406661\n",
      "0.416225\n",
      "0.409541\n",
      "0.435556\n",
      "0.399236\n",
      "0.419416\n",
      "0.419416\n",
      "0.376611\n",
      "0.413845\n",
      "0.383262\n",
      "0.395382\n",
      "0.409051\n",
      "0.405479\n",
      "0.356992\n",
      "0.417577\n",
      "0.419416\n",
      "0.4382\n",
      "0.425655\n",
      "0.420943\n",
      "0.427965\n",
      "0.440974\n",
      "0.435001\n",
      "0.420853\n",
      "0.423156\n",
      "0.430633\n",
      "0.432662\n",
      "0.427965\n",
      "0.401341\n",
      "0.473621\n",
      "0.40143\n",
      "0.399937\n",
      "0.409541\n",
      "0.438813\n",
      "0.419573\n",
      "0.403278\n",
      "0.418062\n",
      "0.449069\n",
      "0.396588\n",
      "0.423851\n",
      "0.391699\n",
      "0.431137\n",
      "0.419055\n",
      "0.421799\n",
      "0.404792\n",
      "0.381896\n",
      "0.428484\n",
      "0.419571\n",
      "0.387367\n",
      "0.413615\n",
      "0.416156\n",
      "0.400587\n",
      "0.427268\n",
      "0.397062\n",
      "0.363702\n",
      "0.46084\n",
      "0.423851\n",
      "0.384198\n",
      "0.409541\n",
      "0.418062\n",
      "0.412468\n",
      "0.418217\n",
      "0.377435\n",
      "0.410887\n",
      "0.398394\n",
      "0.440183\n",
      "0.414129\n",
      "0.447966\n",
      "0.416225\n",
      "0.432452\n",
      "0.407508\n",
      "0.401924\n",
      "0.420943\n",
      "0.409541\n",
      "0.410551\n",
      "0.438112\n",
      "0.418062\n",
      "0.40143\n",
      "0.421833\n",
      "0.401924\n",
      "0.382381\n",
      "0.432088\n",
      "0.368778\n",
      "0.442979\n",
      "0.407157\n",
      "0.409702\n",
      "0.341813\n",
      "0.41209\n",
      "0.37644\n",
      "0.425907\n",
      "0.406661\n",
      "0.419571\n",
      "0.409541\n",
      "0.471687\n",
      "0.450572\n",
      "0.409575\n",
      "0.446809\n",
      "0.373523\n",
      "0.393041\n",
      "0.400587\n",
      "0.424457\n",
      "0.377193\n",
      "0.409541\n",
      "0.414182\n",
      "0.348308\n",
      "0.414148\n",
      "0.37529\n",
      "0.418062\n",
      "0.381429\n",
      "0.397394\n",
      "0.383416\n",
      "0.377933\n",
      "0.409541\n",
      "0.389365\n",
      "0.418217\n",
      "0.365684\n",
      "0.418062\n",
      "0.455661\n",
      "0.409541\n",
      "0.389365\n",
      "0.400412\n",
      "0.436617\n",
      "0.423156\n",
      "0.421833\n",
      "0.397062\n",
      "0.398569\n",
      "0.421799\n",
      "0.464659\n",
      "0.403279\n",
      "0.418217\n",
      "0.365651\n",
      "0.341929\n",
      "0.425655\n",
      "0.384198\n",
      "0.399937\n",
      "0.368181\n",
      "0.405479\n",
      "0.439498\n",
      "0.400587\n",
      "0.423851\n",
      "0.367637\n",
      "0.343129\n",
      "0.423851\n",
      "0.416225\n",
      "0.368659\n",
      "0.409541\n",
      "0.420283\n",
      "0.417701\n",
      "0.432088\n",
      "0.433818\n",
      "0.419416\n",
      "0.392693\n",
      "0.448001\n",
      "0.440109\n",
      "0.409365\n",
      "0.421833\n",
      "0.409541\n",
      "0.413615\n",
      "0.416017\n",
      "0.409541\n",
      "0.405513\n",
      "0.368659\n",
      "0.417701\n",
      "0.383416\n",
      "0.407332\n",
      "0.418062\n",
      "0.394369\n",
      "0.40143\n",
      "0.419089\n",
      "0.421799\n",
      "0.416225\n",
      "0.397306\n",
      "0.416225\n",
      "0.392723\n",
      "0.37529\n",
      "0.421833\n",
      "0.387367\n",
      "0.410391\n",
      "0.464314\n",
      "0.416225\n",
      "0.429738\n",
      "0.417577\n",
      "0.406821\n",
      "0.463095\n",
      "0.387401\n",
      "0.425817\n",
      "0.409541\n",
      "0.442346\n",
      "0.406855\n",
      "0.4136\n",
      "0.409526\n",
      "0.401096\n",
      "0.375219\n",
      "0.35022\n",
      "0.428987\n",
      "0.424941\n",
      "0.390532\n",
      "0.450409\n",
      "0.451367\n",
      "0.420265\n",
      "0.418062\n",
      "0.428537\n",
      "0.423156\n",
      "0.354058\n",
      "0.380482\n",
      "0.428572\n",
      "0.39189\n",
      "0.38586\n",
      "0.418062\n",
      "0.385373\n",
      "0.418217\n",
      "0.409541\n",
      "0.410887\n",
      "0.399745\n",
      "0.427965\n",
      "0.408852\n",
      "0.416225\n",
      "0.40143\n",
      "0.350671\n",
      "0.355651\n",
      "0.405513\n",
      "0.419416\n",
      "0.434154\n",
      "0.427965\n",
      "0.407332\n",
      "0.39189\n",
      "0.408569\n",
      "0.40143\n",
      "0.416671\n",
      "0.398481\n",
      "0.366143\n",
      "0.412177\n",
      "0.416225\n",
      "0.443845\n",
      "0.379913\n",
      "0.355716\n",
      "0.421799\n",
      "0.409541\n",
      "0.395382\n",
      "0.372583\n",
      "0.371524\n",
      "0.419416\n",
      "0.391037\n",
      "0.384542\n",
      "0.419571\n",
      "0.367604\n",
      "0.416225\n",
      "0.377193\n",
      "0.409702\n",
      "0.409541\n",
      "0.421833\n",
      "0.377435\n",
      "0.414217\n",
      "0.384542\n",
      "0.405479\n",
      "0.423886\n",
      "0.42956\n",
      "0.398761\n",
      "0.379897\n",
      "0.409541\n",
      "0.410396\n",
      "0.418062\n",
      "0.395382\n",
      "0.418717\n",
      "0.388531\n",
      "0.405974\n",
      "0.450917\n",
      "0.422316\n",
      "0.409258\n",
      "0.384576\n",
      "0.423566\n",
      "0.423851\n",
      "0.423851\n",
      "0.355984\n",
      "0.368442\n",
      "0.437625\n",
      "0.413615\n",
      "0.418062\n",
      "0.320242\n",
      "0.363702\n",
      "0.420353\n",
      "0.421833\n",
      "0.42264\n",
      "0.419571\n",
      "0.40143\n",
      "0.403119\n",
      "0.384698\n",
      "0.400587\n",
      "0.425907\n",
      "0.4382\n",
      "0.437069\n",
      "0.409541\n",
      "0.455661\n",
      "0.379171\n",
      "0.427965\n",
      "0.372103\n",
      "0.409541\n",
      "0.421104\n",
      "0.409541\n",
      "0.440183\n",
      "0.423851\n",
      "0.419416\n",
      "0.440026\n",
      "0.408357\n",
      "0.409541\n",
      "0.40228\n",
      "0.428484\n",
      "0.368181\n",
      "0.360172\n",
      "0.391924\n",
      "0.383416\n",
      "0.393373\n",
      "0.416848\n",
      "0.392205\n",
      "0.424369\n",
      "0.409541\n",
      "0.379413\n",
      "0.414148\n",
      "0.386362\n",
      "0.406696\n",
      "0.335506\n",
      "0.41209\n",
      "0.418217\n",
      "0.430025\n",
      "0.416678\n",
      "0.431389\n",
      "0.372003\n",
      "0.412177\n",
      "0.419416\n",
      "0.430633\n",
      "0.425907\n",
      "0.3932\n",
      "0.346055\n",
      "0.42203\n",
      "0.4021\n",
      "0.427965\n",
      "0.430025\n",
      "0.450082\n",
      "0.406696\n",
      "0.467334\n",
      "0.409541\n",
      "0.422369\n",
      "0.357915\n",
      "0.370056\n",
      "0.377435\n",
      "0.419416\n",
      "0.377193\n",
      "0.381396\n",
      "0.441481\n",
      "0.407543\n",
      "0.438165\n",
      "0.424214\n",
      "0.404633\n",
      "0.395889\n",
      "0.385201\n",
      "0.393407\n",
      "0.435556\n",
      "0.407226\n",
      "0.4382\n",
      "0.421833\n",
      "0.372702\n",
      "0.407508\n",
      "0.370056\n",
      "0.427965\n",
      "0.409452\n",
      "0.421621\n",
      "0.418062\n",
      "0.39941\n",
      "0.465187\n",
      "0.422995\n",
      "0.40599\n",
      "0.373986\n",
      "0.414839\n",
      "0.425907\n",
      "0.38869\n",
      "0.419416\n",
      "0.415319\n",
      "0.408004\n",
      "0.421139\n",
      "0.451331\n",
      "0.418217\n",
      "0.428484\n",
      "0.428484\n",
      "0.408524\n",
      "0.362232\n",
      "0.414217\n",
      "0.409541\n",
      "0.409541\n",
      "0.421833\n",
      "0.396588\n",
      "0.426158\n",
      "0.408692\n",
      "0.403453\n",
      "0.33055\n",
      "0.425049\n",
      "0.41548\n",
      "0.431262\n",
      "0.411936\n",
      "0.460132\n",
      "0.454921\n",
      "0.39941\n",
      "0.419748\n",
      "0.370535\n",
      "0.465713\n",
      "0.409541\n",
      "0.438813\n",
      "0.397394\n",
      "0.412959\n",
      "0.409541\n",
      "0.383382\n",
      "0.432662\n",
      "0.39792\n",
      "0.434154\n",
      "0.368115\n",
      "0.428572\n",
      "0.414304\n",
      "0.409051\n",
      "0.40143\n",
      "0.417701\n",
      "0.369562\n",
      "0.36159\n",
      "0.416225\n",
      "0.358842\n",
      "0.430025\n",
      "0.418062\n",
      "0.458388\n",
      "0.418062\n",
      "0.392727\n",
      "0.448544\n",
      "0.436761\n",
      "0.419783\n",
      "0.400587\n",
      "0.415657\n",
      "0.415657\n",
      "0.431389\n",
      "0.422841\n",
      "0.456137\n",
      "0.391958\n",
      "0.418062\n",
      "0.44296\n",
      "0.341291\n",
      "0.428572\n",
      "0.415657\n",
      "0.395889\n",
      "0.380758\n",
      "0.404792\n",
      "0.412143\n",
      "0.397886\n",
      "0.40599\n",
      "0.404458\n",
      "0.447838\n",
      "0.473451\n",
      "0.411576\n",
      "0.403453\n",
      "0.399444\n",
      "0.431389\n",
      "0.395889\n",
      "0.403981\n",
      "0.413615\n",
      "0.387367\n",
      "0.403963\n",
      "0.419734\n",
      "0.404465\n",
      "0.421833\n",
      "0.421104\n",
      "0.40977\n",
      "0.379413\n",
      "0.419233\n",
      "0.36616\n",
      "0.411576\n",
      "0.401464\n",
      "0.412924\n",
      "0.426588\n",
      "0.418062\n",
      "0.409541\n",
      "0.481157\n",
      "0.418062\n",
      "0.355331\n",
      "0.435233\n",
      "0.465379\n",
      "0.416225\n",
      "0.419748\n",
      "0.430025\n",
      "0.398481\n",
      "0.423851\n",
      "0.409541\n",
      "0.40143\n",
      "0.428572\n",
      "0.425907\n",
      "0.44296\n",
      "0.425817\n",
      "0.403003\n",
      "0.432088\n",
      "0.381396\n",
      "0.340042\n",
      "0.401992\n",
      "0.418217\n",
      "0.420853\n",
      "0.422478\n",
      "0.320211\n",
      "0.447677\n",
      "0.448001\n",
      "0.378416\n",
      "0.431389\n",
      "0.379931\n",
      "0.375494\n",
      "0.425782\n",
      "0.416225\n",
      "0.365974\n",
      "0.423512\n",
      "0.382743\n",
      "0.341291\n",
      "0.426425\n",
      "0.391194\n",
      "0.419286\n",
      "0.415691\n",
      "0.409541\n",
      "0.449884\n",
      "0.413615\n",
      "0.375975\n",
      "0.411611\n",
      "0.371524\n",
      "0.417239\n",
      "0.444387\n",
      "0.425907\n",
      "0.427965\n",
      "0.409541\n",
      "0.373404\n",
      "0.425729\n",
      "0.39941\n",
      "0.423156\n",
      "0.418217\n",
      "0.415657\n",
      "0.397067\n",
      "0.420265\n",
      "0.441769\n",
      "0.401924\n",
      "0.432697\n",
      "0.4099\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "result_dummy = np.dot(dummy_data, weight)\n",
    "# print result_dummy\n",
    "print result_dummy.shape\n",
    "result_dummy = np.divide(1.0 , 1.0 + np.exp(-result_dummy))\n",
    "# print result.size\n",
    "# print result\n",
    "print result_dummy.shape\n",
    "for i in xrange(0,891):\n",
    "    print result_dummy [i,0]\n",
    "    if result_dummy[i] > 0.5:\n",
    "        \n",
    "        result_dummy[i,0] = 1 \n",
    "    else:\n",
    "        result_dummy[i,0] = 0\n",
    "# print result\n",
    "# res = pids.join(result)\n",
    "result = result_dummy.reshape(891)\n",
    "print result_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data로 계산하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       892\n",
      "1       893\n",
      "2       894\n",
      "3       895\n",
      "4       896\n",
      "5       897\n",
      "6       898\n",
      "7       899\n",
      "8       900\n",
      "9       901\n",
      "10      902\n",
      "11      903\n",
      "12      904\n",
      "13      905\n",
      "14      906\n",
      "15      907\n",
      "16      908\n",
      "17      909\n",
      "18      910\n",
      "19      911\n",
      "20      912\n",
      "21      913\n",
      "22      914\n",
      "23      915\n",
      "24      916\n",
      "25      917\n",
      "26      918\n",
      "27      919\n",
      "28      920\n",
      "29      921\n",
      "       ... \n",
      "388    1280\n",
      "389    1281\n",
      "390    1282\n",
      "391    1283\n",
      "392    1284\n",
      "393    1285\n",
      "394    1286\n",
      "395    1287\n",
      "396    1288\n",
      "397    1289\n",
      "398    1290\n",
      "399    1291\n",
      "400    1292\n",
      "401    1293\n",
      "402    1294\n",
      "403    1295\n",
      "404    1296\n",
      "405    1297\n",
      "406    1298\n",
      "407    1299\n",
      "408    1300\n",
      "409    1301\n",
      "410    1302\n",
      "411    1303\n",
      "412    1304\n",
      "413    1305\n",
      "414    1306\n",
      "415    1307\n",
      "416    1308\n",
      "417    1309\n",
      "Name: PassengerId, dtype: int64\n",
      "0.388638482495\n",
      "0.351578821518\n",
      "0.313816383504\n",
      "0.410782380411\n",
      "0.424478105223\n",
      "0.449984488064\n",
      "0.405052319307\n",
      "0.411520226376\n",
      "0.441083427351\n",
      "0.419767692457\n",
      "0.410782380411\n",
      "0.357780950399\n",
      "0.423808885084\n",
      "0.307237724866\n",
      "0.353763052753\n",
      "0.420707021887\n",
      "0.389353073546\n",
      "0.428766278674\n",
      "0.409518849526\n",
      "0.361451206521\n",
      "0.328672095664\n",
      "0.465257219389\n",
      "0.416303443866\n",
      "0.431111220715\n",
      "0.350954447194\n",
      "0.340239564997\n",
      "0.431329497814\n",
      "0.424250677647\n",
      "0.37204105475\n",
      "0.401895680823\n",
      "0.342298847293\n",
      "0.413021261744\n",
      "0.391788553963\n",
      "0.409518849526\n",
      "0.399749867244\n",
      "0.436318348109\n",
      "0.413980433919\n",
      "0.432001689749\n",
      "0.416753053258\n",
      "0.410782380411\n",
      "0.375563272789\n",
      "0.41310009508\n",
      "0.369808550354\n",
      "0.407261730549\n",
      "0.359410488401\n",
      "0.416753053258\n",
      "0.360613833581\n",
      "0.410782380411\n",
      "0.32210448257\n",
      "0.387388535813\n",
      "0.417593079746\n",
      "0.413001350141\n",
      "0.428233608299\n",
      "0.399983140688\n",
      "0.413001350141\n",
      "0.443940618239\n",
      "0.387177355604\n",
      "0.416753053258\n",
      "0.406331364253\n",
      "0.389661547243\n",
      "0.440864040897\n",
      "0.398166733969\n",
      "0.437832429256\n",
      "0.428984263791\n",
      "0.446283413979\n",
      "0.416204476226\n",
      "0.441083427351\n",
      "0.354957966972\n",
      "0.401217510428\n",
      "0.318095598282\n",
      "0.422965435556\n",
      "0.428766278674\n",
      "0.408021694877\n",
      "0.408631458682\n",
      "0.392592547682\n",
      "0.396790510144\n",
      "0.410782380411\n",
      "0.327520739354\n",
      "0.404079791173\n",
      "0.422965435556\n",
      "0.469863327041\n",
      "0.296945006224\n",
      "0.34934234021\n",
      "0.410782380411\n",
      "0.413001350141\n",
      "0.406331364253\n",
      "0.413980433919\n",
      "0.441083427351\n",
      "0.413980433919\n",
      "0.484429462413\n",
      "0.424478105223\n",
      "0.410782380411\n",
      "0.411834417992\n",
      "0.410782380411\n",
      "0.419080495283\n",
      "0.416753053258\n",
      "0.276986543842\n",
      "0.404837873255\n",
      "0.435024170411\n",
      "0.393033792341\n",
      "0.365097145228\n",
      "0.40854296139\n",
      "0.410782380411\n",
      "0.413764548387\n",
      "0.442611191639\n",
      "0.40780675433\n",
      "0.428766278674\n",
      "0.410782380411\n",
      "0.410782380411\n",
      "0.43857258504\n",
      "0.371945904404\n",
      "0.413980433919\n",
      "0.389661547243\n",
      "0.439566894404\n",
      "0.310140983186\n",
      "0.433303855536\n",
      "0.410782380411\n",
      "0.488512642559\n",
      "0.386527447074\n",
      "0.405786961148\n",
      "0.461635476512\n",
      "0.406331364253\n",
      "0.388208769638\n",
      "0.40780675433\n",
      "0.410782380411\n",
      "0.44411976587\n",
      "0.425754512072\n",
      "0.405072112135\n",
      "0.369075385896\n",
      "0.419747688192\n",
      "0.395973701804\n",
      "0.338236782328\n",
      "0.413980433919\n",
      "0.406331364253\n",
      "0.364090592392\n",
      "0.419747688192\n",
      "0.412272659431\n",
      "0.415988254179\n",
      "0.425972107817\n",
      "0.368385115346\n",
      "0.442651717222\n",
      "0.398477633847\n",
      "0.312589107839\n",
      "0.410020835596\n",
      "0.369170233551\n",
      "0.385747447233\n",
      "0.41310009508\n",
      "0.425754512072\n",
      "0.41310009508\n",
      "0.399652140429\n",
      "0.428313226498\n",
      "0.410782380411\n",
      "0.315822688122\n",
      "0.387388535813\n",
      "0.434845821638\n",
      "0.419747688192\n",
      "0.410334680666\n",
      "0.425972107817\n",
      "0.369170233551\n",
      "0.416969389008\n",
      "0.413980433919\n",
      "0.466798783609\n",
      "0.419198002436\n",
      "0.410782380411\n",
      "0.371945904404\n",
      "0.41249826635\n",
      "0.352145044171\n",
      "0.428786395134\n",
      "0.416303443866\n",
      "0.428984263791\n",
      "0.410782380411\n",
      "0.410782380411\n",
      "0.418259609598\n",
      "0.410782380411\n",
      "0.368385115346\n",
      "0.452473150018\n",
      "0.437276907934\n",
      "0.331393428685\n",
      "0.389564686087\n",
      "0.311450338426\n",
      "0.404079791173\n",
      "0.379267011545\n",
      "0.438902140049\n",
      "0.410782380411\n",
      "0.411834417992\n",
      "0.374825485167\n",
      "0.434250805763\n",
      "0.431803481777\n",
      "0.378740644265\n",
      "0.374825485167\n",
      "0.387900715089\n",
      "0.41310009508\n",
      "0.453042610503\n",
      "0.316472699243\n",
      "0.470602070397\n",
      "0.393033792341\n",
      "0.476840326161\n",
      "0.441083427351\n",
      "0.424985230652\n",
      "0.413980433919\n",
      "0.413980433919\n",
      "0.491878550653\n",
      "0.350751756794\n",
      "0.469301092124\n",
      "0.418981341343\n",
      "0.41310009508\n",
      "0.390313372695\n",
      "0.421980403468\n",
      "0.398477633847\n",
      "0.416753053258\n",
      "0.395973701804\n",
      "0.410782380411\n",
      "0.443123300785\n",
      "0.318007257781\n",
      "0.364334707915\n",
      "0.369170233551\n",
      "0.413980433919\n",
      "0.323263918297\n",
      "0.345368245944\n",
      "0.410782380411\n",
      "0.402822782198\n",
      "0.428766278674\n",
      "0.431229597098\n",
      "0.428766278674\n",
      "0.341197098784\n",
      "0.413980433919\n",
      "0.422748244576\n",
      "0.413980433919\n",
      "0.371243838468\n",
      "0.386430871725\n",
      "0.452252682447\n",
      "0.43435087189\n",
      "0.424260708592\n",
      "0.410782380411\n",
      "0.373489481719\n",
      "0.431783330767\n",
      "0.30471066159\n",
      "0.431783330767\n",
      "0.43880183879\n",
      "0.350954447194\n",
      "0.33568588101\n",
      "0.363568124688\n",
      "0.356377630506\n",
      "0.410782380411\n",
      "0.406331364253\n",
      "0.367747821743\n",
      "0.431229597098\n",
      "0.364796494863\n",
      "0.405786961148\n",
      "0.409518849526\n",
      "0.491047815404\n",
      "0.431783330767\n",
      "0.408641382441\n",
      "0.419747688192\n",
      "0.394502792769\n",
      "0.410782380411\n",
      "0.410782380411\n",
      "0.40780675433\n",
      "0.440307685776\n",
      "0.428766278674\n",
      "0.378463643328\n",
      "0.428766278674\n",
      "0.410236134704\n",
      "0.488512642559\n",
      "0.404079791173\n",
      "0.410782380411\n",
      "0.41310009508\n",
      "0.410782380411\n",
      "0.413980433919\n",
      "0.440864040897\n",
      "0.357780950399\n",
      "0.410782380411\n",
      "0.414818846545\n",
      "0.409518849526\n",
      "0.410782380411\n",
      "0.43274965698\n",
      "0.410020835596\n",
      "0.370519079469\n",
      "0.399652140429\n",
      "0.427995611312\n",
      "0.425972107817\n",
      "0.485984133912\n",
      "0.413980433919\n",
      "0.463958067584\n",
      "0.485437843424\n",
      "0.384261207583\n",
      "0.410782380411\n",
      "0.417593079746\n",
      "0.410782380411\n",
      "0.410782380411\n",
      "0.41310009508\n",
      "0.405052319307\n",
      "0.410782380411\n",
      "0.334126079343\n",
      "0.384261207583\n",
      "0.413764548387\n",
      "0.490801744759\n",
      "0.401895680823\n",
      "0.404177871768\n",
      "0.404837873255\n",
      "0.395973701804\n",
      "0.413001350141\n",
      "0.366214103302\n",
      "0.419747688192\n",
      "0.413980433919\n",
      "0.307513903069\n",
      "0.399749867244\n",
      "0.490340589877\n",
      "0.328672095664\n",
      "0.357210662251\n",
      "0.437832429256\n",
      "0.425754512072\n",
      "0.410782380411\n",
      "0.384471795111\n",
      "0.33568588101\n",
      "0.44411976587\n",
      "0.323263918297\n",
      "0.437057934268\n",
      "0.410782380411\n",
      "0.419001335458\n",
      "0.413764548387\n",
      "0.416753053258\n",
      "0.415988254179\n",
      "0.39531855272\n",
      "0.380916994563\n",
      "0.422748244576\n",
      "0.452493497678\n",
      "0.357780950399\n",
      "0.402608717747\n",
      "0.431011332237\n",
      "0.355068484021\n",
      "0.377809690327\n",
      "0.410782380411\n",
      "0.433522396796\n",
      "0.410782380411\n",
      "0.404177871768\n",
      "0.398166733969\n",
      "0.375563272789\n",
      "0.418981341343\n",
      "0.410782380411\n",
      "0.440088381353\n",
      "0.395973701804\n",
      "0.406331364253\n",
      "0.327502649874\n",
      "0.406331364253\n",
      "0.4471602837\n",
      "0.415988254179\n",
      "0.381563337\n",
      "0.421980403468\n",
      "0.404294108444\n",
      "0.363662372817\n",
      "0.418981341343\n",
      "0.440088381353\n",
      "0.345075011907\n",
      "0.491065396232\n",
      "0.346550010609\n",
      "0.316771158586\n",
      "0.410782380411\n",
      "0.410782380411\n",
      "0.400621176193\n",
      "0.412352265739\n",
      "0.420707021887\n",
      "0.404294108444\n",
      "0.410782380411\n",
      "0.417809539183\n",
      "0.409518849526\n",
      "0.406331364253\n",
      "0.428984263791\n",
      "0.363662372817\n",
      "0.407046915066\n",
      "0.426499784755\n",
      "0.404392205759\n",
      "0.34934234021\n",
      "0.363362227769\n",
      "0.334324109507\n",
      "0.363662372817\n",
      "0.419984466252\n",
      "0.431011332237\n",
      "0.332749229961\n",
      "0.459179471583\n",
      "0.410782380411\n",
      "0.413764548387\n",
      "0.413980433919\n",
      "0.433522396796\n",
      "0.413001350141\n",
      "0.420707021887\n",
      "0.419747688192\n",
      "0.327217002498\n",
      "0.428766278674\n",
      "0.460697841827\n",
      "0.42508476592\n",
      "0.346751569721\n",
      "0.453032434523\n",
      "0.354864716686\n",
      "0.391596076071\n",
      "0.438902140049\n",
      "0.419747688192\n",
      "0.350954447194\n",
      "0.425754512072\n",
      "0.398921148829\n",
      "0.407360055527\n",
      "0.376278256846\n",
      "0.431329497814\n",
      "0.443223809699\n",
      "0.362043421508\n",
      "0.434032178651\n",
      "0.420490145519\n",
      "0.342390548028\n",
      "0.413980433919\n",
      "0.482364146239\n",
      "0.413980433919\n",
      "0.382378935469\n",
      "0.410997800831\n",
      "0.410782380411\n",
      "0.380916994563\n",
      "0.37700753416\n",
      "0.410782380411\n",
      "0.406331364253\n"
     ]
    }
   ],
   "source": [
    "test['Embarked'] = test['Embarked'].fillna(\"S\")\n",
    "test['Pclass'] = test['Pclass'].fillna(1)\n",
    "test[\"Fare\"].fillna(test[\"Fare\"].mean(), inplace=True)\n",
    "test[\"Age\"].fillna(test[\"Age\"].median(), inplace=True)\n",
    "test[\"SibSp\"].fillna(test[\"SibSp\"].median(), inplace=True)\n",
    "test[\"Parch\"].fillna(test[\"Parch\"].median(), inplace=True)\n",
    "\n",
    "dummy_sex = pd.get_dummies(test['Sex'])\n",
    "\n",
    "dummy_pclass = pd.get_dummies(test['Pclass'])\n",
    "\n",
    "pids = test['PassengerId']\n",
    "print (pids)\n",
    "age = test['Age']\n",
    "sibSp = test['SibSp']\n",
    "parch = test['Parch']\n",
    "fare = test['Fare']\n",
    "\n",
    "test_data = dummy_sex.join(dummy_pclass).join(age).join(sibSp)\n",
    "\n",
    "result = np.dot(test_data, weight)\n",
    "result = np.divide(1.0 , 1.0 + np.exp(-result))\n",
    "# print result.size\n",
    "# print result\n",
    "for i in xrange(0,418):\n",
    "    print result [i,0]\n",
    "    if result[i] > 0.4:\n",
    "        \n",
    "        result[i,0] = 1 \n",
    "    else:\n",
    "        result[i,0] = 0\n",
    "# print result\n",
    "# res = pids.join(result)\n",
    "result = result.reshape(418)\n",
    "# print pids.shape, result.reshape(418)\n",
    "\n",
    "# print result\n",
    "pids = pids.as_matrix()\n",
    "# print type(result), type(pids)\n",
    "result_data = pd.DataFrame(data=[pids, result], index=['PassengerId', 'Survived'])\n",
    "\n",
    "result_data = result_data.T\n",
    "result_data['PassengerId'] = result_data['PassengerId'].astype(int)\n",
    "result_data['Survived'] = result_data['Survived'].astype(int)\n",
    "\n",
    "# print result_data.head(10)\n",
    "\n",
    "result_data.to_csv('result_titanic.csv', sep=',', encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
